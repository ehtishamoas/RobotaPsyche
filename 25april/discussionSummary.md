## Reading:
The reading from The Machine Question explores whether and to what extent intelligent and autonomous machines of our own making can be considered to have 
legitimate moral responsibilities and any legitimate claim to moral consideration. The reading addressed the question of machine moral agency: whether a machine 
might be considered a legitimate moral agent that could be held responsible for decisions and actions. Furthermore, it poses a fundamental challenge to moral thinking,
questioning the traditional conceptualization of technology as a tool or instrument to be used by humans.

## Discussion:
On our first question regarding blaming robots, the class stressed that machines must have conscious and rights as citizens (as humans do) in order to blame
them for any incidents.

Then we discussed the idea of ascribing agency to inanimate objects. Some classmates suggested how they are usually inclined to be nice to inanimate objects like 
saying thanks to Siri. Yet, deep in their minds, they always acknowledge that the agency canâ€™t be assigned to them and it actually belongs to their developers.

Furthermore, we reflected upon the reasons why we mostly anticipate conflicts with robots and if coexistence with them can be a possible scenario. 
We talked about how robots will be physically and intellectually superior than us and as we know that we are the ones using up all the resources and 
destroying the planet, we anticipate their logic would fuel their animosity against us. But one perspective was that if we would make robots that would want to 
cooperate with us and we also in turn cooperate with them, then we can definitely coexist with robots.

Regarding our question about the sources of moral code for robots, we discussed how robots can use enormous datasets to learn on their own. 
They can develop a moral code which might be against the views of a particular culture or group of people but supported by others. Hence, we can give them a
particular tailored dataset according to beliefs of a pertinent culture where we will be employing them.

This perspective of human responsibility of robots connected to our next question about human exceptionalism and using robots as tools/slaves.
We discussed that human exceptionalism not necessarily have to mean using robots just as tools, but since we are the ones with agency, we must take 
responsibility of their needs and their actions. Yet, if we reach a point where robots express a desire to not be enslaved, then we must stop doing that
and allow them necessary rights.
